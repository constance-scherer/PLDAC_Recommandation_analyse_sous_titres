{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from preprocessing import *\n",
    "from affichage import *\n",
    "from swSets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lost, Heroes, Jericho, Prison Break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data\"\n",
    "corpus = get_corpus(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la liste:\n",
    "- chaque dictionnaire represente une serie du corpus\n",
    "\n",
    "Dans les dictionnaires:\n",
    "- les cles sont les numeros des saisons\n",
    "- les valeurs sont l'indice max (indMax-1 en fait) des episodes de la saisons dans le dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: 24, 2: 48, 3: 72, 4: 85, 5: 105, 6: 125},\n",
       " {1: 24, 2: 35, 3: 61, 4: 80},\n",
       " {1: 22, 2: 29},\n",
       " {1: 22, 2: 44, 3: 57, 4: 81}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_dict_list = getShowDictList(path)\n",
    "show_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition de l'ensemble de stopwords\n",
    "nltk_sw = set(stopwords.words('english'))\n",
    "sklearn_sw = set(stop_words.ENGLISH_STOP_WORDS)\n",
    "stopwords_set = nltk_sw | sklearn_sw | english_contractions_tokens |sw\n",
    "l_nb = [str(i) for i in range(1000000)]\n",
    "l_mots = [\"don\", \"yeah\", \"hey\", \"okay\", \"oh\", \"uh\", \"yes\", \"ok\"]\n",
    "for mot in l_mots :\n",
    "    stopwords_set.add(mot)\n",
    "for nb in l_nb:\n",
    "    stopwords_set.add(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set, tokenizer=lemmatizing_tokenizer_v2)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "for show_dict in show_dict_list:\n",
    "    show_tfidf_vect_dict = dict()\n",
    "    minInd = 0\n",
    "    for season, maxInd in show_dict.items():\n",
    "        show_tfidf_vect_dict[season] = scipy.sparse.csr_matrix(tfidf_df[minInd:maxInd].values)\n",
    "        minInd= maxInd\n",
    "    dict_list.append(show_tfidf_vect_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la liste:\n",
    "    \n",
    "- chaque dictionnaire represente une serie du corpus\n",
    "\n",
    "Dans les dictionnaires:\n",
    "\n",
    "- les clefs sont les numeros des saisons\n",
    "- les valeurs sont des matrices sparses, dont les lignes sont les vecteurs tf-idf des episodes de la saisons donnée par la clef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: <24x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 10625 stored elements in Compressed Sparse Row format>,\n",
       "  2: <24x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 9610 stored elements in Compressed Sparse Row format>,\n",
       "  3: <24x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 10412 stored elements in Compressed Sparse Row format>,\n",
       "  4: <13x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 6376 stored elements in Compressed Sparse Row format>,\n",
       "  5: <20x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 10827 stored elements in Compressed Sparse Row format>,\n",
       "  6: <20x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 9333 stored elements in Compressed Sparse Row format>},\n",
       " {1: <24x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 10625 stored elements in Compressed Sparse Row format>,\n",
       "  2: <11x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 3812 stored elements in Compressed Sparse Row format>,\n",
       "  3: <26x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 11244 stored elements in Compressed Sparse Row format>,\n",
       "  4: <19x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 9179 stored elements in Compressed Sparse Row format>},\n",
       " {1: <22x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 9529 stored elements in Compressed Sparse Row format>,\n",
       "  2: <7x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 2870 stored elements in Compressed Sparse Row format>},\n",
       " {1: <22x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 9529 stored elements in Compressed Sparse Row format>,\n",
       "  2: <22x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 8604 stored elements in Compressed Sparse Row format>,\n",
       "  3: <13x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 5695 stored elements in Compressed Sparse Row format>,\n",
       "  4: <24x19932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 11483 stored elements in Compressed Sparse Row format>}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarite cosinus entre les episodes de la saisons 1 de Prison Break\n",
    "#similarities_sparse = cosine_similarity(dict_list[3][1] ,dense_output=False)\n",
    "#print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarité cosinus entre NCIS and NCIS Los Angeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello i'd like to report encoding problems\n",
    "\n",
    "\n",
    "<br>\n",
    "Les deux NCIS là: \"ISO-8859-1\" ---> en fait BOF\n",
    "<br>\n",
    "Lost : \"utf-8\"\n",
    "<br>\n",
    "bref à voir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"data\"\n",
    "corpus = get_corpus(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbSeriesCorpus(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: 23,\n",
       "  2: 46,\n",
       "  3: 70,\n",
       "  4: 94,\n",
       "  5: 113,\n",
       "  6: 138,\n",
       "  7: 162,\n",
       "  8: 186,\n",
       "  9: 210,\n",
       "  10: 234,\n",
       "  11: 258,\n",
       "  12: 282,\n",
       "  13: 288},\n",
       " {1: 24, 2: 48, 3: 72, 4: 96, 5: 120, 6: 144, 7: 149}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_dict_list = getShowDictList(path)\n",
    "show_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCIS_texts = list(corpus[:288])\n",
    "LA_texts = list(corpus[288:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "NCIS_str = \"\"\n",
    "for ep in NCIS_texts:\n",
    "    NCIS_str += ep+\" \"\n",
    "c.append(NCIS_str)\n",
    "LA_str = \"\"\n",
    "for ep in LA_texts:\n",
    "       LA_str += ep+\" \"\n",
    "c.append(LA_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set, tokenizer=lemmatizing_tokenizer_v2)\n",
    "X = vectorizer.fit_transform(c)\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = scipy.sparse.csr_matrix(tfidf_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise sparse output:\n",
      "   (0, 1)\t0.687275815227\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 0)\t0.687275815227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarities_sparse = cosine_similarity(sparse_mat ,dense_output=False)\n",
    "print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La similarité cosinus entre NCIS et NCIS Los Angeles est donc : 0.687275815227"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
