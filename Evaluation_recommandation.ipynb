{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation des recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer nos systèmes de recommandations, nous utilisons les notes que les utilisateurs ont données aux séries comme jugement de pertinence (si un utilisateur a mis plus de 7, on met un jugement de pertinence à 1, sinon, il est à 0). \n",
    "Pour chaque utilisateur, on cache une partie des notes qu'il a données et on recommande parmi ces séries là (en prédisant les notes que l'utilisateur va leur donner). On calcule ensuite la nDCG sur la suite de séries ordonnées renvoyée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import collaborative.py ok\n",
      "Import predictions_notes ok\n",
      "Import predictions_content ok\n",
      "Import similarities ok\n",
      "Import ndcg ok\n",
      "Import recommandation ok\n",
      "Import eval_reco.py ok\n"
     ]
    }
   ],
   "source": [
    "from utils.collaborative import *\n",
    "from utils.predictions_content import *\n",
    "from utils.predictions_notes import *\n",
    "from utils.recommandation import *\n",
    "from utils.eval_reco import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_d_user = \"/Users/constancescherer/Desktop/pickles/d_user.p\"\n",
    "#path_sim = \"/Users/constancescherer/Desktop/pickles/sim.p\"\n",
    "#path_most_sim = \"/Users/constancescherer/Desktop/pickles/most_sim.p\"\n",
    "#path_d_pert_user = \"/Users/constancescherer/Desktop/pickles/d_pert_user_k3.p\"\n",
    "\n",
    "path_d_user = \"/Vrac/PLDAC_addic7ed/pickles/d_user.p\"\n",
    "path_sim = \"/Vrac/PLDAC_addic7ed/pickles/sim.p\"\n",
    "path_most_sim = \"/Vrac/PLDAC_addic7ed/pickles/most_sim.p\"\n",
    "path_d_pert_user = \"/Vrac/PLDAC_addic7ed/pickles/d_pert_user_k3.p\"\n",
    "path_d_pop = \"/Vrac/PLDAC_addic7ed/pickles/d_pop.p\"\n",
    "\n",
    "\n",
    "# dictionnaire d_users\n",
    "# {username : {serie : rating}}\n",
    "with open(path_d_user, 'rb') as pickle_file:\n",
    "    d_user = pickle.load(pickle_file)\n",
    "\n",
    "# matrice des similarités cosinus\n",
    "with open(path_sim, 'rb') as pickle_file:\n",
    "    sim = pickle.load(pickle_file)\n",
    "\n",
    "# dictionnaire des séries les plus similaires\n",
    "with open(path_most_sim, 'rb') as pickle_file:\n",
    "    most_similar = pickle.load(pickle_file)\n",
    "    \n",
    "with open(path_d_pert_user, 'rb') as pickle_file:\n",
    "    d_pert_user = pickle.load(pickle_file)\n",
    "    \n",
    "with open(path_d_pop, 'rb') as pickle_file:\n",
    "    d_pop = pickle.load(pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_ratings = \"/Users/constancescherer/Desktop/ratings/ratings_imdb/users\"\n",
    "path_ratings = \"/Vrac/PLDAC_addic7ed/ratings/ratings_imdb/users\"\n",
    "\n",
    "liste_series = get_liste_series(d_user)\n",
    "data = get_data(d_user)\n",
    "all_data, num_user, num_item = get_all_data(data)\n",
    "train, train_mat, test = get_train_test(num_user, num_item, all_data, test_size=10)\n",
    "mean, u_means, i_means,U_ksvd, I_ksvd =  get_Uksvd_Iksvd(train, train_mat, num_user, num_item)\n",
    "d_username_id, d_itemname_id, Full = create_sparse_mat(data)\n",
    "\n",
    "\n",
    "#path_series = \"/Users/constancescherer/Desktop/addic7ed_final\"\n",
    "path_series = '/Vrac/PLDAC_addic7ed/addic7ed_final'\n",
    "\n",
    "d_info, d_name = getDicts(path_series)\n",
    "d_ind = reverse_dict(d_name)\n",
    "d_titre_filename = get_d_titre_filename(\"titles/title-filename.txt\")\n",
    "d_filename_titre = reverse_dict(d_titre_filename)\n",
    "d_id_username = reverse_dict(d_username_id)\n",
    "d_id_serie = reverse_dict(d_itemname_id)\n",
    "\n",
    "reversed_u_dic, reversed_i_dic = create_reversed_dic(d_username_id, d_itemname_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_tr = np.array([rating for (uid,iid),rating in train_mat.items()])\n",
    "truth_te = np.array([rating for uid,iid,rating in test])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 1.4274376744000552\n",
      "MAE: 0.7237943947559603\n",
      "Test Error:\n",
      "MSE: 5.616544363803645\n",
      "MAE: 1.7333823568196423\n"
     ]
    }
   ],
   "source": [
    "prediction_tr = np.array([pred_func_ksvd(u,i, U_ksvd, I_ksvd, u_means, i_means, mean) for (u,i),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_func_ksvd(u,i, U_ksvd, I_ksvd, u_means, i_means, mean) for u,i,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "\n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation kSVD : \n",
      "nDCG en train :  0.9139697999774664\n",
      "nDCG en test :  0.6819401953614532\n"
     ]
    }
   ],
   "source": [
    "print(\"Évaluation kSVD : \")\n",
    "print(\"nDCG en train : \", get_ndcg_moy_train(prediction_tr, train_mat, d_id_username, d_id_serie))\n",
    "print(\"nDCG en test : \", get_ndcg_moy_test(prediction_te, test, d_id_username, d_id_serie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'évaluation des recommandations en test est bien évidemment moins bonne qu'en train mais elle reste assez bonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 0.0\n",
      "MAE: 0.0\n",
      "Test Error:\n",
      "MSE: 8.797942689199118\n",
      "MAE: 2.2909625275532695\n"
     ]
    }
   ],
   "source": [
    "prediction_tr, prediction_te = predictions_NMF(train_mat,test, 100, num_user, num_item)\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "\n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation NMF : \n",
      "nDCG en train :  0.9309231762427372\n",
      "nDCG en test :  0.6810336068066001\n"
     ]
    }
   ],
   "source": [
    "print(\"Évaluation NMF : \")\n",
    "print(\"nDCG en train : \", get_ndcg_moy_train(prediction_tr, train_mat, d_id_username, d_id_serie))\n",
    "print(\"nDCG en test : \", get_ndcg_moy_test(prediction_te, test, d_id_username, d_id_serie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Très similaire au kSVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 3.6669966255748765\n",
      "MAE: 1.3577911121996353\n",
      "Test Error:\n",
      "MSE: 3.663003102294065\n",
      "MAE: 1.3543350477590008\n"
     ]
    }
   ],
   "source": [
    "prediction_tr = np.array([pred_content(u, i, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, sim) for (u,i),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_content(u, i, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, sim) for u,i,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "\n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation content : \n",
      "nDCG en train :  0.9011661655874822\n",
      "nDCG en test :  0.6906627862813159\n"
     ]
    }
   ],
   "source": [
    "print(\"Évaluation content : \")\n",
    "print(\"nDCG en train : \", get_ndcg_moy_train(prediction_tr, train_mat, d_id_username, d_id_serie))\n",
    "print(\"nDCG en test : \", get_ndcg_moy_test(prediction_te, test, d_id_username, d_id_serie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un peu meilleur que le filtrage collaboratif en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'évaluation réalisée donne de bons résulats, mais il est très difficile d'évaluer un système de recommandation. En effet, ici, nous avons recommandé des séries que l'utilisateur avait déjà noté, et non des séries qu'il n'a pas encore vu.  \n",
    "Il faudrait pouvoir noter les recommandations sur des séries que les utilisateurs n'ont pas vu, ce qui est impossible (pour nous, il nous faudrait des feedbacks des utilisateurs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri par popularité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons remarqué un problème dans nos recommandations : on renvoit souvent les mêmes (qui sont en plus des séries assez peu connues - on pense que ce problème vient de leur biais très élevé, car le peu de gens les ayant notées les ont très bien notées).  \n",
    "Pour régler ce problème, nous recourrons à l'heuristique suivante lorsque les notes max prédites pour un utilisateur sont toutes les mêmes : on recommande les séries les plus vues / les mieux notées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation kSVD : \n",
      "nDCG en train :  0.8188542845592465\n",
      "nDCG en test :  0.6879465662783582\n"
     ]
    }
   ],
   "source": [
    "prediction_tr = np.array([pred_func_ksvd(u,i, U_ksvd, I_ksvd, u_means, i_means, mean) for (u,i),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_func_ksvd(u,i, U_ksvd, I_ksvd, u_means, i_means, mean) for u,i,rating in test])\n",
    "\n",
    "print(\"Évaluation kSVD : \")\n",
    "print(\"nDCG en train : \", get_ndcg_moy_train_pop(prediction_tr, train_mat, d_id_username, d_id_serie, d_pop))\n",
    "print(\"nDCG en test : \", get_ndcg_moy_test_pop(prediction_te, test, d_id_username, d_id_serie, d_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation NMF : \n",
      "nDCG en train :  0.8186379987801757\n",
      "nDCG en test :  0.688055286613937\n"
     ]
    }
   ],
   "source": [
    "prediction_tr, prediction_te = predictions_NMF(train_mat,test, 100, num_user, num_item)\n",
    "\n",
    "print(\"Évaluation NMF : \")\n",
    "print(\"nDCG en train : \", get_ndcg_moy_train_pop(prediction_tr, train_mat, d_id_username, d_id_serie, d_pop))\n",
    "print(\"nDCG en test : \", get_ndcg_moy_test_pop(prediction_te, test, d_id_username, d_id_serie, d_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation content : \n",
      "nDCG en train :  0.8190327413361507\n",
      "nDCG en test :  0.6879568289210404\n"
     ]
    }
   ],
   "source": [
    "prediction_tr = np.array([pred_content(u, i, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, sim) for (u,i),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_content(u, i, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, sim) for u,i,rating in test])\n",
    "\n",
    "print(\"Évaluation content : \")\n",
    "print(\"nDCG en train : \", get_ndcg_moy_train_pop(prediction_tr, train_mat, d_id_username, d_id_serie, d_pop))\n",
    "print(\"nDCG en test : \", get_ndcg_moy_test_pop(prediction_te, test, d_id_username, d_id_serie, d_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le tri par popularité, les recommandations sont améliorées en test pour le kSVD et la NMF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
