{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "from utils.preprocessing_cleaned_data import *\n",
    "from utils.swSets import *\n",
    "from sklearn import naive_bayes, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier des épisodes dans la bonne série avec Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec 20 séries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/Vrac/PLDAC_reco/data20\" #20 TV-shows, 3108 episodes\n",
    "#new_dir = \"/Vrac/PLDAC_reco/cleaned_data20\"\n",
    "\n",
    "#createCleanedData(path, new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les séries de notre corpus qui contient 20 séries pour un total de 3108 episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '10___Smallville',\n",
       " 2: '122___Malcolm_In_The_Middle',\n",
       " 3: '12___Doctor_Who',\n",
       " 4: '132___NCIS',\n",
       " 5: '15___House',\n",
       " 6: '16___Desperate_Housewives',\n",
       " 7: '186___American_Dad',\n",
       " 8: '2381___Scandal',\n",
       " 9: '24___Scrubs',\n",
       " 10: '28___Bones',\n",
       " 11: '30___Grey_s_Anatomy',\n",
       " 12: '3103___House_of_Cards_(2013)',\n",
       " 13: '32___Veronica_Mars',\n",
       " 14: '366___True_Blood',\n",
       " 15: '51___How_I_Met_Your_Mother',\n",
       " 16: '57___CSI__Crime_Scene_Investigation',\n",
       " 17: '615___The_Good_Wife',\n",
       " 18: '66___Ugly_Betty',\n",
       " 19: '71___The_Wire',\n",
       " 20: '880___Pretty_Little_Liars'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Vrac/PLDAC_reco/cleaned_data20\"\n",
    "\n",
    "d_info, d_name = getDicts(path)\n",
    "d_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit la matrice de TF-IDF où chaque ligne représente un épisode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_corpus(path, texts_as=\"episode\")\n",
    "X = getTfidfSparseMat(corpus, my_stopwords = stopwords_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On labelise chaque épisode par l'identifiant de la série auquel il appartient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelisation\n",
    "nb_eps_per_show = []\n",
    "for i in range(1, len(d_info.keys())+1):\n",
    "    nb_eps_per_show.append(sum(d_info[i].values()))\n",
    "Y = []\n",
    "nb_shows = len(nb_eps_per_show)\n",
    "somme_cumul = np.cumsum(nb_eps_per_show)\n",
    "indMin = 0\n",
    "for i in range(0, nb_shows):\n",
    "    indMax = somme_cumul[i]\n",
    "    for j in range(indMin, indMax):\n",
    "        Y.append(i+1)\n",
    "    indMin = indMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On instancie un classifieur bayesien naif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes classifier instantiation\n",
    "nb_clf = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la cross-validation pour évaluer le classifieur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 folds :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74562798, 0.76038339, 0.8016129 , 0.79902755, 0.75974026])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 5\n",
    "scores = cross_val_score(nb_clf, X, Y, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy moyenne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.773278416628773"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecart-type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022715506705476406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 folds :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7672956 , 0.7672956 , 0.77777778, 0.77070064, 0.84076433,\n",
       "       0.82315113, 0.83116883, 0.81639344, 0.79207921, 0.75827815])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 10\n",
    "scores = cross_val_score(nb_clf, X, Y, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy moyenne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7944904693709065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecart-type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029033230657270728"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec 50 séries, 5630 épisodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/Vrac/PLDAC_reco/data50\"\n",
    "#new_dir = \"/Vrac/PLDAC_reco/cleaned_data50\"\n",
    "\n",
    "#createCleanedData(path, new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '10___Smallville',\n",
       " 2: '1149___Downton_Abbey',\n",
       " 3: '119___Robin_Hood',\n",
       " 4: '121___Gossip_Girl',\n",
       " 5: '122___Malcolm_In_The_Middle',\n",
       " 6: '12___Doctor_Who',\n",
       " 7: '132___NCIS',\n",
       " 8: '152___Star_Trek__The_Animated_Series',\n",
       " 9: '15___House',\n",
       " 10: '16___Desperate_Housewives',\n",
       " 11: '182___Friends',\n",
       " 12: '186___American_Dad',\n",
       " 13: '1___Lost',\n",
       " 14: '2381___Scandal',\n",
       " 15: '240___Breaking_Bad',\n",
       " 16: '24___Scrubs',\n",
       " 17: '28___Bones',\n",
       " 18: '2964___Vikings',\n",
       " 19: '2___Heroes',\n",
       " 20: '30___Grey_s_Anatomy',\n",
       " 21: '3103___House_of_Cards_(2013)',\n",
       " 22: '32___Veronica_Mars',\n",
       " 23: '334___Buffy_The_Vampire_Slayer',\n",
       " 24: '364___Legend_of_the_Seeker',\n",
       " 25: '366___True_Blood',\n",
       " 26: '376___The_Mentalist',\n",
       " 27: '384___H2O__Just_Add_Water',\n",
       " 28: '3861___Orange_is_the_New_Black',\n",
       " 29: '3990___Peaky_Blinders',\n",
       " 30: '406___Agatha_Christie__Poirot',\n",
       " 31: '4679___Outlander',\n",
       " 32: '46___The_Tudors',\n",
       " 33: '4___Prison_Break',\n",
       " 34: '51___How_I_Met_Your_Mother',\n",
       " 35: '5423___The_Last_Kingdom',\n",
       " 36: '54___Seinfeld',\n",
       " 37: '565___Andromeda',\n",
       " 38: '57___CSI__Crime_Scene_Investigation',\n",
       " 39: '597___Charmed',\n",
       " 40: '5___Supernatural',\n",
       " 41: '600___The_Vampire_Diaries',\n",
       " 42: '615___The_Good_Wife',\n",
       " 43: '630___The_Nanny',\n",
       " 44: '66___Ugly_Betty',\n",
       " 45: '68___Black_Books',\n",
       " 46: '6___Dexter',\n",
       " 47: '71___The_Wire',\n",
       " 48: '73___Rome',\n",
       " 49: '79___The_Office_(UK)',\n",
       " 50: '880___Pretty_Little_Liars'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Vrac/PLDAC_reco/cleaned_data50\"\n",
    "\n",
    "d_info, d_name = getDicts(path)\n",
    "d_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5630"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_eps = 0\n",
    "for info in d_info.values():\n",
    "    nb_eps += sum(list(info.values()))\n",
    "        \n",
    "nb_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_corpus(path, texts_as=\"episode\")\n",
    "X = getTfidfSparseMat(corpus, my_stopwords = stopwords_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelisation\n",
    "nb_eps_per_show = []\n",
    "for i in range(1, len(d_info.keys())+1):\n",
    "    nb_eps_per_show.append(sum(d_info[i].values()))\n",
    "Y = []\n",
    "nb_shows = len(nb_eps_per_show)\n",
    "somme_cumul = np.cumsum(nb_eps_per_show)\n",
    "indMin = 0\n",
    "for i in range(0, nb_shows):\n",
    "    indMax = somme_cumul[i]\n",
    "    for j in range(indMin, indMax):\n",
    "        Y.append(i+1)\n",
    "    indMin = indMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes classifier instantiation\n",
    "nb_clf = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6451049 , 0.69859402, 0.74156306, 0.74103943, 0.71066908])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 5\n",
    "scores = cross_val_score(nb_clf, X, Y, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7073940958105228"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.65523156, 0.67525773, 0.70383275, 0.7122807 , 0.76460177,\n",
       "       0.75222816, 0.74820144, 0.75362319, 0.74542125, 0.7245841 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 10\n",
    "scores = cross_val_score(nb_clf, X, Y, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723526265731068"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045520698672970476"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moins bonne accuracy avec 50 séries mais certaines séries dans ce corpus contiennent trop peu d'épisodes (par rapport au corpus de 20 séries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentative de recommandation avec Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Idée :</b> \n",
    "- Entrainer le classifieur d'épisodes sur un ensemble de séries.  \n",
    "- Prendre une série hors de cet ensemble.\n",
    "- Tenter de classifier ses épisodes dans les séries aprises par le classifieur.\n",
    "- Renvoyer la série apparaissant le plus dans les classifications comme étant la plus proche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_test = \"/Vrac/PLDAC_reco/data_reco_bayes\"\n",
    "#new_dir_test = \"/Vrac/PLDAC_reco/cleaned_data_reco_bayes\"\n",
    "\n",
    "#createCleanedData(path_test, new_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"/Vrac/PLDAC_reco/cleaned_data_reco_bayes\"\n",
    "\n",
    "corpus = get_corpus(path_test, texts_as=\"episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_info, d_name = getDicts(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_eps = 0\n",
    "for i in range(50, 58):\n",
    "    nb_eps += sum(list(d_info[i].values()))\n",
    "        \n",
    "nb_eps    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = getTfidfSparseMat(corpus, my_stopwords = stopwords_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6096x125664 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4371841 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[:-457]\n",
    "X2 = X[-457:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_info, d_name = getDicts(path_test)\n",
    "\n",
    "for i in range(50, 58):\n",
    "    del d_info[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '108___Mad_Men',\n",
       " 2: '10___Smallville',\n",
       " 3: '1149___Downton_Abbey',\n",
       " 4: '119___Robin_Hood',\n",
       " 5: '121___Gossip_Girl',\n",
       " 6: '122___Malcolm_In_The_Middle',\n",
       " 7: '12___Doctor_Who',\n",
       " 8: '132___NCIS',\n",
       " 9: '152___Star_Trek__The_Animated_Series',\n",
       " 10: '15___House',\n",
       " 11: '16___Desperate_Housewives',\n",
       " 12: '182___Friends',\n",
       " 13: '186___American_Dad',\n",
       " 14: '1___Lost',\n",
       " 15: '2381___Scandal',\n",
       " 16: '240___Breaking_Bad',\n",
       " 17: '24___Scrubs',\n",
       " 18: '262___Only_Fools_and_Horses',\n",
       " 19: '2766___Major_Crimes',\n",
       " 20: '28___Bones',\n",
       " 21: '2964___Vikings',\n",
       " 22: '2___Heroes',\n",
       " 23: '30___Grey_s_Anatomy',\n",
       " 24: '3103___House_of_Cards_(2013)',\n",
       " 25: '32___Veronica_Mars',\n",
       " 26: '334___Buffy_The_Vampire_Slayer',\n",
       " 27: '364___Legend_of_the_Seeker',\n",
       " 28: '366___True_Blood',\n",
       " 29: '376___The_Mentalist',\n",
       " 30: '384___H2O__Just_Add_Water',\n",
       " 31: '3861___Orange_is_the_New_Black',\n",
       " 32: '3990___Peaky_Blinders',\n",
       " 33: '406___Agatha_Christie__Poirot',\n",
       " 34: '4679___Outlander',\n",
       " 35: '46___The_Tudors',\n",
       " 36: '48___Everybody_Hates_Chris',\n",
       " 37: '4___Prison_Break',\n",
       " 38: '51___How_I_Met_Your_Mother',\n",
       " 39: '5423___The_Last_Kingdom',\n",
       " 40: '54___Seinfeld',\n",
       " 41: '55___The_Sopranos',\n",
       " 42: '565___Andromeda',\n",
       " 43: '57___CSI__Crime_Scene_Investigation',\n",
       " 44: '597___Charmed',\n",
       " 45: '5___Supernatural',\n",
       " 46: '600___The_Vampire_Diaries',\n",
       " 47: '615___The_Good_Wife',\n",
       " 48: '630___The_Nanny',\n",
       " 49: '66___Ugly_Betty',\n",
       " 50: '68___Black_Books',\n",
       " 51: '6___Dexter',\n",
       " 52: '71___The_Wire',\n",
       " 53: '73___Rome',\n",
       " 54: '793___The_League_of_Gentlemen',\n",
       " 55: '79___The_Office_(UK)',\n",
       " 56: '880___Pretty_Little_Liars',\n",
       " 57: '95___Sex___the_City'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelisation\n",
    "nb_eps_per_show = []\n",
    "for i in range(1, len(d_info.keys())+1):\n",
    "    nb_eps_per_show.append(sum(d_info[i].values()))\n",
    "Y = []\n",
    "nb_shows = len(nb_eps_per_show)\n",
    "somme_cumul = np.cumsum(nb_eps_per_show)\n",
    "indMin = 0\n",
    "for i in range(0, nb_shows):\n",
    "    indMax = somme_cumul[i]\n",
    "    for j in range(indMin, indMax):\n",
    "        Y.append(i+1)\n",
    "    indMin = indMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naives Bayes classifier instantiation\n",
    "nb_clf = naive_bayes.MultinomialNB()\n",
    "\n",
    "nb_clf.fit(X1, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb_clf.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 23, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 23, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8, 43, 43, 43, 43, 43, 43, 23, 43, 23, 23, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 23, 23, 23, 23, 43,\n",
       "       43, 23, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 23, 43, 43, 43, 43, 43, 43, 43, 23, 43, 43, 43, 23, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 23, 23, 43, 23, 23, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 23, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 11, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 12, 43, 43, 43, 43, 11, 43, 43, 23, 23, 23,\n",
       "       23, 43, 43, 43, 43, 43, 43, 12, 43, 43, 43, 43, 43, 23, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 23, 23, 23, 23, 23, 23, 23, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 23, 23, 23, 23, 43, 23, 23, 23, 12,\n",
       "       23, 23, 23, 23, 12, 23, 12, 23, 12, 23,  8, 12, 43, 43, 43, 23, 12,\n",
       "       23, 23, 23, 43, 43, 23, 43, 43, 23, 23, 23, 43, 43, 43, 23])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne marche pas, (biais chelou quelque part ? ou alors idée nulle) à revoir\n",
    "\n",
    "Dans les prédictions, on ne retrouve que quelques séries. Ces séries ayant beaucoup de saisons et d'épisodes par saison, elles aspirent les recommandations avec le classifieur naiveBayes. Voir avec un SVM (discriminant) si les résultats changent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_info, d_name = getDicts(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = 0\n",
    "pred_series = []\n",
    "for idSerie in range(50, 58) :\n",
    "    dico_saisons = d_info[idSerie]\n",
    "    pred_saisons = []\n",
    "    for idSaison in dico_saisons :\n",
    "        nb_ep = dico_saisons[idSaison]\n",
    "        for idSerieReco in predictions[cpt:cpt+nb_ep]:\n",
    "            pred_saisons.append(idSerieReco)\n",
    "        \n",
    "        cpt += nb_ep\n",
    "    pred_series.append(pred_saisons)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 43, 43, 8, 43, 43, 43, 43]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "l = []\n",
    "for idSerie in range(0, len(pred_series)) :\n",
    "    liste_series_recommandees = pred_series[idSerie]\n",
    "    dico_series = dict.fromkeys(set(liste_series_recommandees), 0)\n",
    "    for idSerieReco in liste_series_recommandees :\n",
    "        dico_series[idSerieReco] += 1\n",
    "    m = max(dico_series.items(), key=operator.itemgetter(1))[0]\n",
    "    l.append(m)\n",
    "\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 68___Black_Books\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 6___Dexter\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 71___The_Wire\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 73___Rome\n",
      "\n",
      "\tvous aimerez sûrement la série 132___NCIS\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 793___The_League_of_Gentlemen\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 79___The_Office_(UK)\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 880___Pretty_Little_Liars\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 95___Sex___the_City\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idSerie in range(50, 58) :\n",
    "    print(\"-----------------------------------------------------------------------\\n\")\n",
    "    nomSerie = d_name[idSerie]\n",
    "    print(\"Si vous avez aimé la série \"+str(nomSerie)+\"\\n\")\n",
    "    idSerieReco = l[idSerie-50]\n",
    "    nomSerieReco = d_name[idSerieReco]\n",
    "    print(\"\\tvous aimerez sûrement la série \"+str(nomSerieReco)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparemment, la série CSI est une très bonne recommandation de série."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
