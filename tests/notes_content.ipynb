{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©diction de notes par contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import dok_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import sqeuclidean, cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take as input two lists of ratings\n",
    "\n",
    "def MSE_err(truth,pred):\n",
    "    \"\"\"\n",
    "    computes MSE from real-pred difference\n",
    "    \"\"\"\n",
    "    return np.mean((truth-pred)**2)\n",
    "\n",
    "def MAE_err(truth,pred):\n",
    "    \"\"\"\n",
    "    computes MAE from real-pred difference\n",
    "    \"\"\"\n",
    "    return np.mean(abs(np.array(truth-pred)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Vrac/PLDAC_addic7ed/ratings/ratings_60'\n",
    "#path = \"/Users/constancescherer/Desktop/ratings/ratings_60\"\n",
    "#path = \"ratings_60\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_user = dict() #{username : {serie: note, serie : note}}\n",
    "\n",
    "for user in sorted(os.listdir(path)):\n",
    "    username = re.sub(\".txt\", \"\", user)\n",
    "    d_user[username] = dict()\n",
    "    with open(path+\"/\"+user) as file: \n",
    "        lignes = file.readlines()\n",
    "        for ligne in lignes :\n",
    "            serie, rating = ligne.split(\" \")\n",
    "            rating = rating.rstrip(\"\\n\")\n",
    "            rating = float(rating)\n",
    "            \n",
    "            d_user[username][serie] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_series = set()\n",
    "for username, d_s in d_user.items() :\n",
    "    for serie, rating in d_s.items() :\n",
    "        liste_series.add(serie)\n",
    "liste_series = list(liste_series)\n",
    "len(liste_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for username, d_s in d_user.items() :\n",
    "    for serie, rating in d_s.items() :\n",
    "        data.append( (username, serie, rating) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BeneCumb', 'the-prisoner', 8.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 users and 1357 items.\n"
     ]
    }
   ],
   "source": [
    "# We first remap users and item to ids between (0,len(user)) and (0,len(item))\n",
    "u_dic = {} #{username : user id}\n",
    "i_dic = {} #{item title : item id}\n",
    "        \n",
    "all_data = [] #[(user id, item id, rating)]\n",
    "    \n",
    "d_username_id = dict()\n",
    "d_itemname_id = dict()\n",
    "for uid,iid,rating in data:  # iterating on all data\n",
    "    \n",
    "    uk = u_dic.setdefault(uid,len(u_dic))\n",
    "    ik = i_dic.setdefault(iid,len(i_dic))\n",
    "    all_data.append((uk,ik,float(rating)))\n",
    "    d_username_id[uid] = uk\n",
    "    d_itemname_id[iid] = ik\n",
    "\n",
    "num_user = len(u_dic)\n",
    "num_item = len(i_dic)\n",
    "\n",
    "print(str(num_user)+\" users and \"+str(num_item)+\" items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Create sparse matrix from all ratings\n",
    "Full = dok_matrix((num_user, num_item), dtype=np.float32)\n",
    "\n",
    "for uid,iid,rating in all_data:\n",
    "    Full[uid,iid] = float(rating)\n",
    "    \n",
    "    \n",
    "# (2) Factorizing matrix\n",
    "\n",
    "model = NMF(n_components=25, init='random', random_state=0, max_iter=350)\n",
    "U = model.fit_transform(Full) #users\n",
    "I = model.components_      #items\n",
    "\n",
    "I = I.transpose()\n",
    "I.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples:  3305\n",
      "Number of test examples:  368\n"
     ]
    }
   ],
   "source": [
    "# We take 10% of the train set as test data\n",
    "train_mat = dok_matrix((num_user, num_item), dtype=np.float32)\n",
    "test = []\n",
    "train = []\n",
    "    \n",
    "for i,(uid,iid,rating) in enumerate(all_data):\n",
    "    if i%10 == 0: #one out of 10 is for test\n",
    "        test.append((uid,iid,rating))\n",
    "    else:\n",
    "        train.append((uid,iid,rating))\n",
    "        train_mat[uid,iid] = rating\n",
    "    \n",
    "print(\"Number of train examples: \", train_mat.nnz)\n",
    "print(\"Number of test examples: \", len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/Vrac/PLDAC_addic7ed/sim.p\", 'rb') as pickle_file:\n",
    "    similarities = pickle.load(pickle_file)\n",
    "\n",
    "with open(\"/Vrac/PLDAC_addic7ed/pickle_most_similar.p\", 'rb') as pickle_file:\n",
    "    most_similar = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3279"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDicts2(path):\n",
    "    res = dict() #  keys : show id     values: dict(key:id season, value: nb  ep season)\n",
    "    res2 = dict() # keys : show id     values: show title\n",
    "    j = 0\n",
    "    filenames= sorted(os.listdir(path)) # get all files' and folders' names in the current directory\n",
    "    for filename in filenames: # loop through all the files and folders\n",
    "        if filename[0] == '.' :\n",
    "            continue\n",
    "        if os.path.isdir(os.path.join(os.path.abspath(path), filename)): # check whether the current object is a folder or not\n",
    "            show_path = path+\"/\"+filename\n",
    "            l = []\n",
    "            nb_saisons = sum(os.path.isdir(os.path.join(show_path, i)) for i in sorted(os.listdir(show_path)))\n",
    "            for season in sorted(os.listdir(show_path)):\n",
    "                if season[0] == '.' :\n",
    "                    continue\n",
    "                season_path = show_path+\"/\"+season\n",
    "                nb_eps_saison = len(fnmatch.filter(os.listdir(season_path), '*.txt'))\n",
    "                l.append(nb_eps_saison)\n",
    "            seasons_list = list(range(1, nb_saisons+1))\n",
    "            dico_serie = dict(zip(seasons_list, l))\n",
    "            res[j] = dico_serie\n",
    "            res2[j] = filename\n",
    "            j += 1\n",
    "    \n",
    "    return res, res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_series = '/Vrac/PLDAC_addic7ed/addic7ed_clean'\n",
    "d_info, d_name = getDicts(path_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000___Battlestar_Galactica__The_Face_of_the_Enemy'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ind = {v: k for k, v in d_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ind['1000___Battlestar_Galactica__The_Face_of_the_Enemy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_titre_filename = dict()\n",
    "with open(\"titles/title-filename.txt\") as file :\n",
    "\tlignes = file.readlines()\n",
    "\tfor ligne in lignes :\n",
    "\t\tl = ligne.split(\" \")\n",
    "\t\ttitre = l[0]\n",
    "\t\tfilename = l[1].rstrip('\\n')\n",
    "\t\td_titre_filename[titre] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filename_titre = {v: k for k, v in d_titre_filename.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_id_username = {v: k for k, v in u_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_id_serie = {v: k for k, v in i_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_content(uid, iid, k=3):\n",
    "    \"\"\"\n",
    "    pr√©dire la note de l'utilisateur uid pour la serie iid \n",
    "    (moyenne sur les k ppv de iid chez uid)\n",
    "    \"\"\"\n",
    "    \n",
    "    # r√©cup√©rer toutes les s√©ries not√©es par uid\n",
    "    u = d_id_username[uid]\n",
    "    series_notes = d_user[u]\n",
    "    series = series_notes.keys()\n",
    "    #notes = series_notes.values()\n",
    "    \n",
    "    # r√©cup√©rer le vecteur de similarit√© entre iid et toutes les autres s√©ries\n",
    "    i = d_id_serie[iid]\n",
    "    f = d_titre_filename[i]\n",
    "    n_iid = -1\n",
    "    if f in d_ind.keys() :\n",
    "        n_iid = d_ind[f]\n",
    "    \n",
    "    simil = similarities[n_iid]\n",
    "    \n",
    "    # on parcourt les s√©ries que l'utilisateur a vu\n",
    "    series_ind = []\n",
    "    for s in series :\n",
    "        f = d_titre_filename[s]\n",
    "        if f in d_ind.keys() :\n",
    "            series_ind.append(d_ind[f])\n",
    "        \n",
    "    \n",
    "    d_simil = {}\n",
    "    for ind in series_ind :\n",
    "        d_simil[ind] = simil[ind]\n",
    "    \n",
    "    \n",
    "    sorted_x = sorted(d_simil.items(), key=lambda kv: kv[1])\n",
    "    sorted_x.reverse()\n",
    "     \n",
    "    sorted_dict = OrderedDict(sorted_x)\n",
    "    \n",
    "    series_plus_similaires = list(sorted_dict)\n",
    "    \n",
    "    kppv = series_plus_similaires[:k]\n",
    "    \n",
    "    notes = []\n",
    "    \n",
    "    for ind in kppv :\n",
    "        f = d_name[ind]\n",
    "        t = d_filename_titre[f]\n",
    "        n = series_notes[t]\n",
    "        notes.append(n)\n",
    "        \n",
    "    return np.mean(notes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 2.903378719112455\n",
      "MAE: 1.2027231467473525\n",
      "Test Error:\n",
      "MSE: 2.612922705314009\n",
      "MAE: 1.1539855072463767\n"
     ]
    }
   ],
   "source": [
    "## Getting the truth values\n",
    "truth_tr = np.array([rating for (uid,iid),rating in train_mat.items()])\n",
    "truth_te = np.array([rating for uid,iid,rating in test])\n",
    "\n",
    "prediction_tr = np.array([pred_content(u, i) for (u,i),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_content(u, i) for u,i,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "    \n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
