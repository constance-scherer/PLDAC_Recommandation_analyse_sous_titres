{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkred'> Clustering sur les épisodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import math\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_ligne(ligne):\n",
    "    \"\"\"\n",
    "    return True si la ligne est un sous-titre, False sinon\n",
    "    \"\"\"\n",
    "    timestamp_regex = r'[0-9]{2}:[0-9]{2}:[0-9]{2}' \n",
    "    subnumber_regex =r'^[0-9]+$'\n",
    "    liste_regex = [timestamp_regex, subnumber_regex]\n",
    "\n",
    "    for regex in liste_regex:\n",
    "        if re.match(regex, ligne):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def preprocessing_fichier(nom_fichier) :\n",
    "    \"\"\"\n",
    "    string -> string\n",
    "    à partir du nom d'un fichier de sous-titres, renvoie le texte des sous-titres\n",
    "    \"\"\"\n",
    "    fichier = open(nom_fichier, 'r', encoding = \"ISO-8859-1\")\n",
    "    lignes = fichier.readlines()\n",
    "    fichier.close()\n",
    "    texte = \"\"\n",
    "    for ligne in lignes :\n",
    "        if verifier_ligne(ligne) :\n",
    "\n",
    "            m = re.sub(r'[^\\w'+\"-\"']', ' ', ligne)\n",
    "            \n",
    "            texte += m\n",
    "    \n",
    "    return texte\n",
    "\n",
    "\n",
    "def scan_folder(parent_folder, corp):\n",
    "    \"\"\"\n",
    "    retourne corpus des textes contenus dans parent_folder sous forme de liste de string\n",
    "    \"\"\"\n",
    "    # iterate over all the files in directory 'parent_folder'\n",
    "    for file_name in os.listdir(parent_folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            path = parent_folder+\"/\"+file_name\n",
    "            \n",
    "            texte = preprocessing_fichier(path)\n",
    "            \n",
    "            corp.append(texte)\n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((parent_folder, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recall this method\n",
    "                scan_folder(current_path, corp)\n",
    "    \n",
    "    return corp\n",
    "\n",
    "\n",
    "#pour eviter les variables globales\n",
    "def get_corpus(parent_folder):\n",
    "    c = []\n",
    "    res = scan_folder(parent_folder, c)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_hist(df, x_axis, y_axis, titre, colour, font_size=None, horizontal=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if horizontal:\n",
    "        hist = df.plot.barh(x=x_axis, y=y_axis, color=colour, title =titre, fontsize = font_size, edgecolor = \"none\").get_figure()\n",
    "    else:\n",
    "        hist = df.plot.bar(x=x_axis, y=y_axis, color=colour, title =titre, fontsize = font_size, edgecolor = \"none\").get_figure()\n",
    "    path_fig = \"img/\"+titre+'.png'\n",
    "    hist.savefig(path_fig,  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> Clustering par saison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut voir si l'algo des kMeans est capable de différencier les épisodes de la saison 1 d'Avatar de la saison 2 de la même série en se basant sur les tf-idf des mots par rapport aux deux saisons.\n",
    "\n",
    "<br></br>\n",
    "<font color='red'>Matrice des tf-idf : par rapport à la saison de référence ou par rapport aux deux saisons ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_corpus(\"/Vrac/PLDAC_addic7ed/data/175___Avatar__The_Last_Airbender/01\") # liste des épisodes\n",
    "corpus += get_corpus(\"/Vrac/PLDAC_addic7ed/data/175___Avatar__The_Last_Airbender/02\")\n",
    "#definition de l'ensemble de stopwords\n",
    "nltk_sw = set(stopwords.words('english'))\n",
    "sklearn_sw = set(stop_words.ENGLISH_STOP_WORDS)\n",
    "stopwords_set = nltk_sw | sklearn_sw\n",
    "l_nb = [str(i) for i in range(1000000)]\n",
    "l_mots = [\"don\", \"yeah\", \"hey\", \"okay\", \"oh\", \"uh\", \"yes\", \"ok\"]\n",
    "for mot in l_mots :\n",
    "    stopwords_set.add(mot)\n",
    "for nb in l_nb:\n",
    "    stopwords_set.add(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dico = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels corrects pour calculer l'accuracy\n",
    "# 1 = saison 1\n",
    "# 0 = saison 2\n",
    "\n",
    "y = []\n",
    "for i in range(0, 21) :\n",
    "    y.append(1)\n",
    "for i in range(0, 20) :\n",
    "    y.append(0)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_tfidf = df_tfidf.values\n",
    "# pour la transformer en sparse matrix\n",
    "sparse_matrix_tfidf = sparse.csr_matrix(matrix_tfidf)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(sparse_matrix_tfidf)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "cpt = 0\n",
    "for i in range(0, len(labels)) :\n",
    "    if y[i] == labels[i] :\n",
    "        cpt += 1\n",
    "print(\"Accuracy = \"+str(cpt/len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cet exemple en particulier, l'accuracy est très bonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> Clustering par série"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut voir la même chose qu'avant mais cette fois-ci entre les épisodes de deux séries différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'> Séries très différentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premiers tests sur deux séries très différentes :\n",
    "- Lost\n",
    "- Avatar\n",
    "\n",
    "On s'attend à de bons résultats : le vocabulaire employé dans les deux séries est très différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = get_corpus(\"/Vrac/PLDAC_addic7ed/data/175___Avatar__The_Last_Airbender/01\") # liste des épisodes\n",
    "corpus2 = get_corpus(\"/Vrac/PLDAC_addic7ed/data/1___Lost/01\")\n",
    "corpus = corpus1 + corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for i in range(0, len(corpus1)) :\n",
    "    y.append(0)\n",
    "for i in range(0, len(corpus2)) :\n",
    "    y.append(1)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dico = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_tfidf = df_tfidf.values\n",
    "# pour la transformer en sparse matrix\n",
    "sparse_matrix_tfidf = sparse.csr_matrix(matrix_tfidf)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(sparse_matrix_tfidf)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 0 classé dans le groupe : 0\n",
      "Épisode 1 classé dans le groupe : 0\n",
      "Épisode 2 classé dans le groupe : 0\n",
      "Épisode 3 classé dans le groupe : 0\n",
      "Épisode 4 classé dans le groupe : 0\n",
      "Épisode 5 classé dans le groupe : 0\n",
      "Épisode 6 classé dans le groupe : 0\n",
      "Épisode 7 classé dans le groupe : 0\n",
      "Épisode 8 classé dans le groupe : 0\n",
      "Épisode 9 classé dans le groupe : 0\n",
      "Épisode 10 classé dans le groupe : 0\n",
      "Épisode 11 classé dans le groupe : 0\n",
      "Épisode 12 classé dans le groupe : 0\n",
      "Épisode 13 classé dans le groupe : 0\n",
      "Épisode 14 classé dans le groupe : 0\n",
      "Épisode 15 classé dans le groupe : 0\n",
      "Épisode 16 classé dans le groupe : 0\n",
      "Épisode 17 classé dans le groupe : 0\n",
      "Épisode 18 classé dans le groupe : 0\n",
      "Épisode 19 classé dans le groupe : 0\n",
      "Épisode 20 classé dans le groupe : 0\n",
      "Épisode 21 classé dans le groupe : 1\n",
      "Épisode 22 classé dans le groupe : 1\n",
      "Épisode 23 classé dans le groupe : 1\n",
      "Épisode 24 classé dans le groupe : 1\n",
      "Épisode 25 classé dans le groupe : 1\n",
      "Épisode 26 classé dans le groupe : 1\n",
      "Épisode 27 classé dans le groupe : 1\n",
      "Épisode 28 classé dans le groupe : 1\n",
      "Épisode 29 classé dans le groupe : 1\n",
      "Épisode 30 classé dans le groupe : 1\n",
      "Épisode 31 classé dans le groupe : 1\n",
      "Épisode 32 classé dans le groupe : 1\n",
      "Épisode 33 classé dans le groupe : 1\n",
      "Épisode 34 classé dans le groupe : 1\n",
      "Épisode 35 classé dans le groupe : 1\n",
      "Épisode 36 classé dans le groupe : 1\n",
      "Épisode 37 classé dans le groupe : 1\n",
      "Épisode 38 classé dans le groupe : 1\n",
      "Épisode 39 classé dans le groupe : 1\n",
      "Épisode 40 classé dans le groupe : 1\n",
      "Épisode 41 classé dans le groupe : 1\n",
      "Épisode 42 classé dans le groupe : 1\n",
      "Épisode 43 classé dans le groupe : 1\n",
      "Épisode 44 classé dans le groupe : 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(labels)) :\n",
    "    print(\"Épisode \"+str(i)+\" classé dans le groupe : \"+str(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "cpt = 0\n",
    "for i in range(0, len(labels)) :\n",
    "    if y[i] == labels[i] :\n",
    "        cpt += 1\n",
    "print(\"Accuracy = \"+str(cpt/len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ces deux séries, l'algorithme des kMeans avoir parfaitement à diviser les deux groupes par rapport aux tf-idf des mots présents dans les épisodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'> Séries très similaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse maintenant à deux séries avec un vocabulaire plus similaire.\n",
    "- Dr House\n",
    "- Grey's Anatomy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_serie1 =\"/Vrac/PLDAC_addic7ed/data/30___Grey_s_Anatomy/01\"\n",
    "path_serie2 = \"/Vrac/PLDAC_addic7ed/addic7ed/15___House/01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = get_corpus(path_serie1)\n",
    "corpus2 = get_corpus(path_serie2)\n",
    "corpus = corpus1 + corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for i in range(0, len(corpus1)) :\n",
    "    y.append(1)\n",
    "for i in range(0, len(corpus2)) :\n",
    "    y.append(0)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dico = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_tfidf = df_tfidf.values\n",
    "# pour la transformer en sparse matrix\n",
    "sparse_matrix_tfidf = sparse.csr_matrix(matrix_tfidf)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(sparse_matrix_tfidf)\n",
    "labels = kmeans.labels_\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 0 classé dans le groupe : 1\n",
      "Épisode 1 classé dans le groupe : 1\n",
      "Épisode 2 classé dans le groupe : 1\n",
      "Épisode 3 classé dans le groupe : 1\n",
      "Épisode 4 classé dans le groupe : 1\n",
      "Épisode 5 classé dans le groupe : 1\n",
      "Épisode 6 classé dans le groupe : 1\n",
      "Épisode 7 classé dans le groupe : 1\n",
      "Épisode 8 classé dans le groupe : 1\n",
      "Épisode 9 classé dans le groupe : 0\n",
      "Épisode 10 classé dans le groupe : 0\n",
      "Épisode 11 classé dans le groupe : 0\n",
      "Épisode 12 classé dans le groupe : 0\n",
      "Épisode 13 classé dans le groupe : 0\n",
      "Épisode 14 classé dans le groupe : 0\n",
      "Épisode 15 classé dans le groupe : 0\n",
      "Épisode 16 classé dans le groupe : 0\n",
      "Épisode 17 classé dans le groupe : 0\n",
      "Épisode 18 classé dans le groupe : 0\n",
      "Épisode 19 classé dans le groupe : 0\n",
      "Épisode 20 classé dans le groupe : 0\n",
      "Épisode 21 classé dans le groupe : 0\n",
      "Épisode 22 classé dans le groupe : 0\n",
      "Épisode 23 classé dans le groupe : 0\n",
      "Épisode 24 classé dans le groupe : 0\n",
      "Épisode 25 classé dans le groupe : 0\n",
      "Épisode 26 classé dans le groupe : 0\n",
      "Épisode 27 classé dans le groupe : 0\n",
      "Épisode 28 classé dans le groupe : 0\n",
      "Épisode 29 classé dans le groupe : 0\n",
      "Épisode 30 classé dans le groupe : 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(labels)) :\n",
    "    print(\"Épisode \"+str(i)+\" classé dans le groupe : \"+str(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "cpt = 0\n",
    "for i in range(0, len(labels)) :\n",
    "    if y[i] == labels[i] :\n",
    "        cpt += 1\n",
    "print(\"Accuracy = \"+str(cpt/len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toujours une accuracy de 1. Sûrement du à la présence des noms propres qui doivent permettre une bonne discrimination des épisodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> Problèmes des noms propres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pimenter un peu la classification, on va essayer d'enlever les noms propres, qui sont très discriminants pour différencier deux épisodes de séries différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_serie1 =\"/Vrac/PLDAC_addic7ed/data/30___Grey_s_Anatomy/01\"\n",
    "path_serie2 = \"/Vrac/PLDAC_addic7ed/addic7ed/15___House/01\"\n",
    "corpus1 = get_corpus(path_serie1)\n",
    "corpus2 = get_corpus(path_serie2)\n",
    "corpus = corpus1 + corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(0, len(corpus1)) :\n",
    "    y.append(1)\n",
    "for i in range(0, len(corpus2)) :\n",
    "    y.append(0)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dico = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "      <th>top4</th>\n",
       "      <th>top5</th>\n",
       "      <th>top6</th>\n",
       "      <th>top7</th>\n",
       "      <th>top8</th>\n",
       "      <th>top9</th>\n",
       "      <th>top10</th>\n",
       "      <th>top11</th>\n",
       "      <th>top12</th>\n",
       "      <th>top13</th>\n",
       "      <th>top14</th>\n",
       "      <th>top15</th>\n",
       "      <th>top16</th>\n",
       "      <th>top17</th>\n",
       "      <th>top18</th>\n",
       "      <th>top19</th>\n",
       "      <th>top20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>james</td>\n",
       "      <td>twitch</td>\n",
       "      <td>tuberculoma</td>\n",
       "      <td>whoah</td>\n",
       "      <td>wrist</td>\n",
       "      <td>know</td>\n",
       "      <td>victoria</td>\n",
       "      <td>mri</td>\n",
       "      <td>homeless</td>\n",
       "      <td>pin</td>\n",
       "      <td>foreman</td>\n",
       "      <td>fury</td>\n",
       "      <td>meningitis</td>\n",
       "      <td>like</td>\n",
       "      <td>got</td>\n",
       "      <td>streets</td>\n",
       "      <td>terharg</td>\n",
       "      <td>prozac</td>\n",
       "      <td>right</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mark</td>\n",
       "      <td>attack</td>\n",
       "      <td>alzheimer</td>\n",
       "      <td>stacy</td>\n",
       "      <td>paris</td>\n",
       "      <td>yoga</td>\n",
       "      <td>want</td>\n",
       "      <td>think</td>\n",
       "      <td>blah</td>\n",
       "      <td>aip</td>\n",
       "      <td>know</td>\n",
       "      <td>right</td>\n",
       "      <td>gregg</td>\n",
       "      <td>like</td>\n",
       "      <td>going</td>\n",
       "      <td>encephalitis</td>\n",
       "      <td>warner</td>\n",
       "      <td>mountain</td>\n",
       "      <td>paranoia</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>meningitis</td>\n",
       "      <td>know</td>\n",
       "      <td>need</td>\n",
       "      <td>rash</td>\n",
       "      <td>going</td>\n",
       "      <td>right</td>\n",
       "      <td>like</td>\n",
       "      <td>form</td>\n",
       "      <td>neck</td>\n",
       "      <td>mary</td>\n",
       "      <td>blue</td>\n",
       "      <td>ow</td>\n",
       "      <td>bleeding</td>\n",
       "      <td>interview</td>\n",
       "      <td>blood</td>\n",
       "      <td>area</td>\n",
       "      <td>interviewing</td>\n",
       "      <td>brenda</td>\n",
       "      <td>puncture</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dvt</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>mom</td>\n",
       "      <td>vitamin</td>\n",
       "      <td>luke</td>\n",
       "      <td>know</td>\n",
       "      <td>old</td>\n",
       "      <td>gonna</td>\n",
       "      <td>birthday</td>\n",
       "      <td>right</td>\n",
       "      <td>think</td>\n",
       "      <td>ampicillin</td>\n",
       "      <td>pickles</td>\n",
       "      <td>schizophrenic</td>\n",
       "      <td>pt</td>\n",
       "      <td>young</td>\n",
       "      <td>dr</td>\n",
       "      <td>blood</td>\n",
       "      <td>shrink</td>\n",
       "      <td>praise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>matt</td>\n",
       "      <td>chi</td>\n",
       "      <td>hydrolase</td>\n",
       "      <td>kid</td>\n",
       "      <td>davis</td>\n",
       "      <td>poisoned</td>\n",
       "      <td>know</td>\n",
       "      <td>son</td>\n",
       "      <td>time</td>\n",
       "      <td>clothes</td>\n",
       "      <td>cdc</td>\n",
       "      <td>tomato</td>\n",
       "      <td>got</td>\n",
       "      <td>poison</td>\n",
       "      <td>bus</td>\n",
       "      <td>washed</td>\n",
       "      <td>pesticides</td>\n",
       "      <td>mom</td>\n",
       "      <td>make</td>\n",
       "      <td>detergent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          top1           top2         top3     top4   top5      top6  \\\n",
       "26       james         twitch  tuberculoma    whoah  wrist      know   \n",
       "27        mark         attack    alzheimer    stacy  paris      yoga   \n",
       "28  meningitis           know         need     rash  going     right   \n",
       "29         dvt  schizophrenia          mom  vitamin   luke      know   \n",
       "30        matt            chi    hydrolase      kid  davis  poisoned   \n",
       "\n",
       "        top7   top8      top9    top10    top11       top12       top13  \\\n",
       "26  victoria    mri  homeless      pin  foreman        fury  meningitis   \n",
       "27      want  think      blah      aip     know       right       gregg   \n",
       "28      like   form      neck     mary     blue          ow    bleeding   \n",
       "29       old  gonna  birthday    right    think  ampicillin     pickles   \n",
       "30      know    son      time  clothes      cdc      tomato         got   \n",
       "\n",
       "            top14  top15         top16         top17     top18     top19  \\\n",
       "26           like    got       streets       terharg    prozac     right   \n",
       "27           like  going  encephalitis        warner  mountain  paranoia   \n",
       "28      interview  blood          area  interviewing    brenda  puncture   \n",
       "29  schizophrenic     pt         young            dr     blood    shrink   \n",
       "30         poison    bus        washed    pesticides       mom      make   \n",
       "\n",
       "        top20  \n",
       "26  treatment  \n",
       "27      house  \n",
       "28        old  \n",
       "29     praise  \n",
       "30  detergent  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlargest = 20\n",
    "order = np.argsort(-df_tfidf.values, axis=1)[:, :nlargest]\n",
    "result = pd.DataFrame(df_tfidf.columns[order], \n",
    "                      columns=['top{}'.format(i) for i in range(1, nlargest+1)],\n",
    "                      index=df_tfidf.index)\n",
    "result.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les tf-idf les plus élevés sont très souvent des noms propres.\n",
    "\n",
    "Le but va être de les éliminer pour chaque épisode afin de voir si les kMeans peuvent différencier sur autre chose.\n",
    "\n",
    "Dans un premier temps, on enlève, pour chaque épisode, les 20 mots dont les tf-idf sont les plus grands. C'est peut-être un peu trop, on ajustera après.\n",
    "\n",
    "Il faut soit remplacer le tf-idf de ces mots par autre chose ou bien les enlever du vocabulaire pour tous les épisodes.\n",
    "- remplacer : par un 0 ? un nombre aléatoire ? autre chose ?\n",
    "        -> on veut que ces mots ne soient plus discriminants pour la classification\n",
    "- enlever : on récupère pour chaque épisode les 20 mots avec les plus grands tf-idf et on crée un ensemble puis on enlève tous ces mots dans tous les épisodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'> Élimination du dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère pour chaque épisode les 20 mots avec les plus grands tf-idf et on crée un ensemble puis on enlève tous ces mots dans tous les épisodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noms = result.values\n",
    "set_noms_propres = set()\n",
    "for ep in noms :\n",
    "    for mot in ep :\n",
    "        set_noms_propres.add(mot)\n",
    "liste_noms_propres = list(set_noms_propres)\n",
    "len(liste_noms_propres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00am</th>\n",
       "      <th>03</th>\n",
       "      <th>100l65</th>\n",
       "      <th>100mg</th>\n",
       "      <th>11th</th>\n",
       "      <th>150s</th>\n",
       "      <th>16th</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebras</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zit</th>\n",
       "      <th>zits</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ªclickâ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.175171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000       007      00am   03    100l65  100mg  11th  150s  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.020857    0.0   0.0   0.0   \n",
       "1  0.059528  0.000000  0.000000  0.018101  0.0  0.000000    0.0   0.0   0.0   \n",
       "2  0.000000  0.011254  0.175171  0.000000  0.0  0.000000    0.0   0.0   0.0   \n",
       "3  0.012743  0.000000  0.000000  0.000000  0.0  0.000000    0.0   0.0   0.0   \n",
       "4  0.058782  0.000000  0.000000  0.000000  0.0  0.000000    0.0   0.0   0.0   \n",
       "\n",
       "   16th  ...  yummy  yup  zebra    zebras  zero  zeros  zit  zits  zoo  \\\n",
       "0   0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "1   0.0  ...    0.0  0.0    0.0  0.016155   0.0    0.0  0.0   0.0  0.0   \n",
       "2   0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "3   0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "4   0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "\n",
       "   ªclickâ  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 9198 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_tfidf.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00am</th>\n",
       "      <th>03</th>\n",
       "      <th>100l65</th>\n",
       "      <th>100mg</th>\n",
       "      <th>11th</th>\n",
       "      <th>150s</th>\n",
       "      <th>16th</th>\n",
       "      <th>1980s</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebras</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zit</th>\n",
       "      <th>zits</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ªclickâ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000      00am   03    100l65  100mg  11th  150s  16th  \\\n",
       "0  0.000000  0.000000  0.000000  0.0  0.020857    0.0   0.0   0.0   0.0   \n",
       "1  0.059528  0.000000  0.018101  0.0  0.000000    0.0   0.0   0.0   0.0   \n",
       "2  0.000000  0.011254  0.000000  0.0  0.000000    0.0   0.0   0.0   0.0   \n",
       "3  0.012743  0.000000  0.000000  0.0  0.000000    0.0   0.0   0.0   0.0   \n",
       "4  0.058782  0.000000  0.000000  0.0  0.000000    0.0   0.0   0.0   0.0   \n",
       "\n",
       "   1980s  ...  yummy  yup  zebra    zebras  zero  zeros  zit  zits  zoo  \\\n",
       "0    0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "1    0.0  ...    0.0  0.0    0.0  0.016155   0.0    0.0  0.0   0.0  0.0   \n",
       "2    0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "3    0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "4    0.0  ...    0.0  0.0    0.0  0.000000   0.0    0.0  0.0   0.0  0.0   \n",
       "\n",
       "   ªclickâ  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 8804 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pour se débarasser des colonnes\n",
    "for mot in liste_noms_propres :\n",
    "    df_copy = df_copy.drop(mot, axis=1)\n",
    "    \n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_set)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dico = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for i in range(0, len(corpus1)) :\n",
    "    y.append(1)\n",
    "for i in range(0, len(corpus2)) :\n",
    "    y.append(0)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_tfidf = df_tfidf.values\n",
    "# pour la transformer en sparse matrix\n",
    "sparse_matrix_tfidf = sparse.csr_matrix(matrix_tfidf)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(sparse_matrix_tfidf)\n",
    "labels = kmeans.labels_\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 0 classé dans le groupe : 1\n",
      "Épisode 1 classé dans le groupe : 1\n",
      "Épisode 2 classé dans le groupe : 1\n",
      "Épisode 3 classé dans le groupe : 1\n",
      "Épisode 4 classé dans le groupe : 1\n",
      "Épisode 5 classé dans le groupe : 1\n",
      "Épisode 6 classé dans le groupe : 1\n",
      "Épisode 7 classé dans le groupe : 1\n",
      "Épisode 8 classé dans le groupe : 1\n",
      "Épisode 9 classé dans le groupe : 0\n",
      "Épisode 10 classé dans le groupe : 0\n",
      "Épisode 11 classé dans le groupe : 0\n",
      "Épisode 12 classé dans le groupe : 0\n",
      "Épisode 13 classé dans le groupe : 0\n",
      "Épisode 14 classé dans le groupe : 0\n",
      "Épisode 15 classé dans le groupe : 0\n",
      "Épisode 16 classé dans le groupe : 0\n",
      "Épisode 17 classé dans le groupe : 0\n",
      "Épisode 18 classé dans le groupe : 0\n",
      "Épisode 19 classé dans le groupe : 0\n",
      "Épisode 20 classé dans le groupe : 0\n",
      "Épisode 21 classé dans le groupe : 0\n",
      "Épisode 22 classé dans le groupe : 0\n",
      "Épisode 23 classé dans le groupe : 0\n",
      "Épisode 24 classé dans le groupe : 0\n",
      "Épisode 25 classé dans le groupe : 0\n",
      "Épisode 26 classé dans le groupe : 0\n",
      "Épisode 27 classé dans le groupe : 0\n",
      "Épisode 28 classé dans le groupe : 0\n",
      "Épisode 29 classé dans le groupe : 0\n",
      "Épisode 30 classé dans le groupe : 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(labels)) :\n",
    "    print(\"Épisode \"+str(i)+\" classé dans le groupe : \"+str(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "cpt = 0\n",
    "for i in range(0, len(labels)) :\n",
    "    if y[i] == labels[i] :\n",
    "        cpt += 1\n",
    "print(\"Accuracy = \"+str(cpt/len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toujours une accuracy de 1 :o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'> Des petites fonctions propres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif_deux_series(path_serie1, path_serie2, stopwords_set) :\n",
    "    \"\"\"\n",
    "    pour classifier deux séries\n",
    "    \"\"\"\n",
    "    path_serie1 =\"/Vrac/PLDAC_addic7ed/data/30___Grey_s_Anatomy/01\"\n",
    "    path_serie2 = \"/Vrac/PLDAC_addic7ed/addic7ed/15___House/01\"\n",
    "    corpus1 = get_corpus(path_serie1)\n",
    "    corpus2 = get_corpus(path_serie2)\n",
    "    corpus = corpus1 + corpus2\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords_set)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dico = vectorizer.get_feature_names()\n",
    "    dense = X.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df_tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
    "    \n",
    "    \n",
    "    matrix_tfidf = df_tfidf.values\n",
    "    # pour la transformer en sparse matrix\n",
    "    sparse_matrix_tfidf = sparse.csr_matrix(matrix_tfidf)\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(sparse_matrix_tfidf)\n",
    "    \n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, y) :\n",
    "    \"\"\"\n",
    "    labels : labels prédis \n",
    "    y : labels corrects\n",
    "    renvoie l'accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    cpt = 0\n",
    "    for i in range(0, len(labels)) :\n",
    "        if y[i] == labels[i] :\n",
    "            cpt += 1\n",
    "    \n",
    "    return cpt/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
