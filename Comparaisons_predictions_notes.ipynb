{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaisons entre différentes manières de prédiction de notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook présente la MSE et la MAE pour différentes façons de prédire les notes d'utilisateurs sur des séries.  \n",
    "4000 utilisateurs pour 3000 séries.  \n",
    "Au moins 4 notes pour chacun des utilisateurs.  \n",
    "Les différents algorithmes comparés :\n",
    "- kSVD\n",
    "- NMF\n",
    "    - sans biais\n",
    "    - avec biais\n",
    "- content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.recommandation_errors import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ratings = \"/Vrac/PLDAC_addic7ed/ratings/ratings_imdb/users\"\n",
    "#path_ratings = \"/Users/constancescherer/Desktop/ratings/ratings_imdb/users\"\n",
    "path_d_user = \"/Vrac/PLDAC_addic7ed/pickles/d_user.p\"\n",
    "#path_d_user = \"/Users/constancescherer/Desktop/pickles/d_user.p\"\n",
    "#d_user= get_d_user(path)\n",
    "with open(path_d_user, 'rb') as pickle_file:\n",
    "    d_user = pickle.load(pickle_file)\n",
    "\n",
    "liste_series = get_liste_series(d_user)\n",
    "data = get_data(d_user)\n",
    "all_data, num_user, num_item = get_all_data(data)\n",
    "train, train_mat, test = get_train_test(num_user, num_item, all_data, test_size=20)\n",
    "mean, u_means, i_means,U_ksvd, I_ksvd =  get_Uksvd_Iksvd(train, train_mat, num_user, num_item)\n",
    "d_username_id, d_itemname_id, Full = create_sparse_mat(data)\n",
    "\n",
    "#path_series = \"/Users/constancescherer/Desktop/addic7ed_final\"\n",
    "path_series = '/Vrac/PLDAC_addic7ed/addic7ed_final'\n",
    "d_info, d_name = getDicts(path_series)\n",
    "d_ind = reverse_dict(d_name)\n",
    "d_titre_filename = get_d_titre_filename(\"titles/title-filename.txt\")\n",
    "d_filename_titre = reverse_dict(d_titre_filename)\n",
    "d_id_username = reverse_dict(d_username_id)\n",
    "d_id_serie = reverse_dict(d_itemname_id)\n",
    "\n",
    "path_sim = \"/Vrac/PLDAC_addic7ed/pickles/sim.p\"\n",
    "#path_sim = \"/Users/constancescherer/Desktop/pickles/sim.p\"\n",
    "# matrice des similarités cosinus\n",
    "with open(path_sim, 'rb') as pickle_file:\n",
    "    similarities = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 8.105694\n",
      "MAE: 2.3358402\n",
      "Test Error:\n",
      "MSE: 8.277842351522526\n",
      "MAE: 2.373684267889131\n"
     ]
    }
   ],
   "source": [
    "error_mean_only(train_mat, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 1.4717542445892757\n",
      "MAE: 0.7410327440155239\n",
      "Test Error:\n",
      "MSE: 5.641115231844463\n",
      "MAE: 1.716289295576649\n"
     ]
    }
   ],
   "source": [
    "error_ksvd(train_mat, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 0.0029776867\n",
      "MAE: 0.0029776867\n",
      "Test Error:\n",
      "MSE: 8.944893460690668\n",
      "MAE: 2.3056576047024246\n"
     ]
    }
   ],
   "source": [
    "error_NMF(train_mat, test, num_user, num_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 0.0020495765\n",
      "MAE: 0.0020495765\n",
      "Test Error:\n",
      "MSE: 8.84276267450404\n",
      "MAE: 2.2858192505510653\n"
     ]
    }
   ],
   "source": [
    "error_NMF(train_mat, test, num_user, num_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu6/3520166/PLDAC_Recommandation_analyse_sous_titres-master/utils/collaborative.py:180: RuntimeWarning: Mean of empty slice.\n",
      "  item_mean = np.array(list(item.values())).mean()\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 2.0061487296492517\n",
      "MAE: 0.6923314900034804\n",
      "Test Error:\n",
      "MSE: 6.0911094783247615\n",
      "MAE: 1.6869948567229978\n"
     ]
    }
   ],
   "source": [
    "error_NMF_biais(train_mat,test, 100, num_user, num_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "MSE: 3.6745684932389757\n",
      "MAE: 1.3577477860706137\n",
      "Test Error:\n",
      "MSE: 3.6009470160829453\n",
      "MAE: 1.3543962772471223\n"
     ]
    }
   ],
   "source": [
    "error_content(train_mat, test, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_content_return(train_mat, test, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, similarities) :\n",
    "    \"\"\"returns train and test error for content based recommandation with user/item biases using MSE and MAE metrics\"\"\"\n",
    "    truth_tr = np.array([rating for (uid,iid),rating in train_mat.items()])\n",
    "    truth_te = np.array([rating for uid,iid,rating in test])\n",
    "\n",
    "    prediction_tr = np.array([pred_content(u, i, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, similarities) for (u,i),rating in train_mat.items()])\n",
    "    prediction_te = np.array([pred_content(u, i, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, similarities) for u,i,rating in test])\n",
    "\n",
    "\n",
    "    return MSE_err(prediction_tr,truth_tr), MAE_err(prediction_tr,truth_tr), MSE_err(prediction_te,truth_te), MAE_err(prediction_te,truth_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train_er = []\n",
    "mae_train_er = []\n",
    "mse_test_er = []\n",
    "mae_test_er = []\n",
    "for size in range(100000, 600000, 100000):\n",
    "    similarities = pickle.load(open(\"/Vrac/PLDAC_reco/pickles/sim/sim_voc_\"+str(size)+\".p\", \"rb\"))\n",
    "    mse_train, mae_train, mse_test, mae_test = error_content_return(train_mat, test, d_name, d_user, d_ind, d_titre_filename, d_filename_titre, d_id_username, d_id_serie, similarities)\n",
    "    mse_train_er.append(mse_train)\n",
    "    mae_train_er.append(mae_train)\n",
    "    mse_test_er.append(mse_test)\n",
    "    mae_test_er.append(mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3639480773940729,\n",
       " 1.3622336517266715,\n",
       " 1.3614988978692137,\n",
       " 1.3627234876316432,\n",
       " 1.3639480773940729]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_test_er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille du vocabulaire n'influe pas trop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kSVD et content donnent de bons résultats en test.\n",
    "\n",
    "La NMF sans biais est mauvaise en test (sur apprentissage) mais elle ne prend pas en compte les biais des utilisateurs et des items (contrairement au kSVD).\n",
    "La NMF avec biais est meilleur que le kSVD.\n",
    "Les prédictions des notes par rapport au contenu sont les meilleures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
