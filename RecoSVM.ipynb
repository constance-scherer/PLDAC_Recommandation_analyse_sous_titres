{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from utils.preprocessing import *\n",
    "from utils.swSets import *\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommandation avec SVM\n",
    "\n",
    "<b>Idée :</b> \n",
    "- Entrainer le classifieur d'épisodes sur un ensemble de séries.  \n",
    "- Prendre une série hors de cet ensemble.\n",
    "- Tenter de classifier ses épisodes dans les séries aprises par le classifieur.\n",
    "- Renvoyer la série apparaissant le plus dans les classifications comme étant la plus proche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Vrac/PLDAC_reco/data_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_corpus(path, texts_as=\"episodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_info_train, d_name_train = getDicts(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '103___The_Dead_Zone',\n",
       " 1: '104___Las_Vegas',\n",
       " 2: '10___Smallville',\n",
       " 3: '12___Doctor_Who',\n",
       " 4: '14___Oz',\n",
       " 5: '15___House',\n",
       " 6: '16___Desperate_Housewives',\n",
       " 7: '17___The_Shield',\n",
       " 8: '1___Lost',\n",
       " 9: '20___The_L_Word',\n",
       " 10: '21___Criminal_Minds',\n",
       " 11: '240___Breaking_Bad',\n",
       " 12: '24___Scrubs',\n",
       " 13: '28___Bones',\n",
       " 14: '29___Gilmore_Girls',\n",
       " 15: '30___Grey_s_Anatomy',\n",
       " 16: '47___Psych',\n",
       " 17: '51___How_I_Met_Your_Mother',\n",
       " 18: '52___Entourage',\n",
       " 19: '53___ER',\n",
       " 20: '54___Seinfeld',\n",
       " 21: '55___The_Sopranos',\n",
       " 22: '57___CSI__Crime_Scene_Investigation',\n",
       " 23: '5___Supernatural',\n",
       " 24: '61___Robot_Chicken',\n",
       " 25: '64___One_Tree_Hill',\n",
       " 26: '65___The_Office_(US)',\n",
       " 27: '6___Dexter',\n",
       " 28: '74___Numb3rs',\n",
       " 29: '77___Nip_Tuck',\n",
       " 30: '78___30_Rock',\n",
       " 31: '7___24',\n",
       " 32: '81___Weeds',\n",
       " 33: '82___Monk',\n",
       " 34: '85___The_X-Files',\n",
       " 35: '86___Two_and_a_Half_Men',\n",
       " 36: '90___The_Closer',\n",
       " 37: '91___Magnum__P.I.',\n",
       " 38: '95___Sex___the_City',\n",
       " 39: '96___Curb_Your_Enthusiasm'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_name_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille vocabulaire :  134627\n"
     ]
    }
   ],
   "source": [
    "X, vec = getTfidfSparseMatVectorizer(corpus, my_stopwords=stopwords_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_eps_per_show = []\n",
    "for i in range(0, len(d_info_train.keys())):\n",
    "    nb_eps_per_show.append(sum(d_info_train[i].values()))\n",
    "#labelisation\n",
    "Y = []\n",
    "nb_shows = len(nb_eps_per_show)\n",
    "somme_cumul = np.cumsum(nb_eps_per_show)\n",
    "indMin = 0\n",
    "for i in range(0, nb_shows):\n",
    "    indMax = somme_cumul[i]\n",
    "    for j in range(indMin, indMax):\n",
    "        Y.append(i)\n",
    "    indMin = indMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm_clf = svm.LinearSVC()\n",
    "lsvm_clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"/Vrac/PLDAC_reco/data_test\"\n",
    "c_test = get_corpus(path_test, texts_as=\"episodes\")\n",
    "X2 = vec.transform(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lsvm_clf.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_info_test, d_name_test = getDicts(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_eps_per_show = []\n",
    "for i in range(0, len(d_info_test.keys())):\n",
    "    nb_eps_per_show.append(sum(d_info_test[i].values()))\n",
    "#labelisation\n",
    "Y_test = []\n",
    "nb_shows = len(nb_eps_per_show)\n",
    "somme_cumul = np.cumsum(nb_eps_per_show)\n",
    "indMin = 0\n",
    "for i in range(0, nb_shows):\n",
    "    indMax = somme_cumul[i]\n",
    "    for j in range(indMin, indMax):\n",
    "        Y_test.append(i)\n",
    "    indMin = indMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def most_frequent(List): \n",
    "    counter = 0\n",
    "    num = List[0] \n",
    "      \n",
    "    for i in List: \n",
    "        curr_frequency = List.count(i) \n",
    "        if(curr_frequency> counter): \n",
    "            counter = curr_frequency \n",
    "            num = i \n",
    "  \n",
    "    return num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "indmin = 0\n",
    "pred = []\n",
    "for i in d_name_test.keys():\n",
    "    l = list(predictions[indmin : indmin+nb_eps_per_show[i]])\n",
    "    pred.append(most_frequent(l))\n",
    "    indmin = indmin+nb_eps_per_show[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 24, 22, 3, 14, 31, 3, 3, 24, 26, 16, 3, 3, 6, 10, 21, 35, 10, 3, 19]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 22___Friday_Night_Lights\n",
      "\n",
      "\tvous aimerez sûrement la série 64___One_Tree_Hill\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 31___My_Name_Is_Earl\n",
      "\n",
      "\tvous aimerez sûrement la série 61___Robot_Chicken\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 32___Veronica_Mars\n",
      "\n",
      "\tvous aimerez sûrement la série 57___CSI__Crime_Scene_Investigation\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 33___Stargate_Atlantis\n",
      "\n",
      "\tvous aimerez sûrement la série 12___Doctor_Who\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 37___The_O.C.\n",
      "\n",
      "\tvous aimerez sûrement la série 29___Gilmore_Girls\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 40___The_Unit\n",
      "\n",
      "\tvous aimerez sûrement la série 7___24\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 43___The_IT_Crowd\n",
      "\n",
      "\tvous aimerez sûrement la série 12___Doctor_Who\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 46___The_Tudors\n",
      "\n",
      "\tvous aimerez sûrement la série 12___Doctor_Who\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 48___Everybody_Hates_Chris\n",
      "\n",
      "\tvous aimerez sûrement la série 61___Robot_Chicken\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 4___Prison_Break\n",
      "\n",
      "\tvous aimerez sûrement la série 65___The_Office_(US)\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 56___The_4400\n",
      "\n",
      "\tvous aimerez sûrement la série 47___Psych\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 60___Primeval\n",
      "\n",
      "\tvous aimerez sûrement la série 12___Doctor_Who\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 63___Torchwood\n",
      "\n",
      "\tvous aimerez sûrement la série 12___Doctor_Who\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 66___Ugly_Betty\n",
      "\n",
      "\tvous aimerez sûrement la série 16___Desperate_Housewives\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 70___Daria\n",
      "\n",
      "\tvous aimerez sûrement la série 21___Criminal_Minds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 71___The_Wire\n",
      "\n",
      "\tvous aimerez sûrement la série 55___The_Sopranos\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 72___Boston_Legal\n",
      "\n",
      "\tvous aimerez sûrement la série 86___Two_and_a_Half_Men\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 76___Big_Love\n",
      "\n",
      "\tvous aimerez sûrement la série 21___Criminal_Minds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 87___Battlestar_Galactica\n",
      "\n",
      "\tvous aimerez sûrement la série 12___Doctor_Who\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Si vous avez aimé la série 94___Eureka\n",
      "\n",
      "\tvous aimerez sûrement la série 53___ER\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred)):\n",
    "    print(\"-----------------------------------------------------------------------\\n\")\n",
    "    nomSerie = d_name_test[i]\n",
    "    print(\"Si vous avez aimé la série \"+str(nomSerie)+\"\\n\")\n",
    "    idSerieReco = pred[i]\n",
    "    nomSerieReco = d_name_train[idSerieReco]\n",
    "    print(\"\\tvous aimerez sûrement la série \"+str(nomSerieReco)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
